{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de gráficos\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar Datos Procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos procesados\n",
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "y_train = pd.read_csv('../data/processed/y_train.csv')\n",
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "y_test = pd.read_csv('../data/processed/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los datos de entrenamiento: (454902, 8) (454902, 1)\n",
      "Tamaño de los datos de prueba: (56962, 8) (56962, 1)\n"
     ]
    }
   ],
   "source": [
    "# Inspección de los datos cargados\n",
    "print(\"Tamaño de los datos de entrenamiento:\", X_train.shape, y_train.shape)\n",
    "print(\"Tamaño de los datos de prueba:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenar y Evaluar Diferentes Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelos y sus hiperparámetros\n",
    "models_with_params = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"model\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "        \"params\": {\n",
    "            \"C\": [0.01, 0.1, 1, 10],\n",
    "            \"penalty\": [\"l1\", \"l2\"],\n",
    "            \"solver\": [\"liblinear\"]\n",
    "        }\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        \"model\": DecisionTreeClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"max_depth\": [None, 10, 20, 30],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 2, 4]\n",
    "        }\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"max_depth\": [None, 10, 20],\n",
    "            \"min_samples_split\": [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    \"Support Vector Machine\": {\n",
    "        \"model\": SVC(random_state=42, probability=True),\n",
    "        \"params\": {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"kernel\": [\"linear\", \"rbf\"]\n",
    "        }\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"max_depth\": [3, 5, 10],\n",
    "            \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar y evaluar cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando y evaluando: Logistic Regression\n",
      "\n",
      "Entrenando y evaluando: Decision Tree\n"
     ]
    }
   ],
   "source": [
    "# Entrenar modelos y seleccionar el mejor\n",
    "results = []\n",
    "best_model = None\n",
    "best_model_name = None\n",
    "best_score = 0\n",
    "\n",
    "for model_name, model_details in models_with_params.items():\n",
    "    print(f\"\\nEntrenando y evaluando: {model_name}\")\n",
    "    model = model_details[\"model\"]\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    # Calcular métricas\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob) if y_prob is not None else None\n",
    "\n",
    "    # Guardar resultados\n",
    "    results.append({\n",
    "        \"Modelo\": model_name,\n",
    "        \"F1-Score\": f1,\n",
    "        \"ROC-AUC\": roc_auc\n",
    "    })\n",
    "\n",
    "    # Seleccionar el mejor modelo dinámicamente\n",
    "    if f1 > best_score:\n",
    "        best_model = model\n",
    "        best_model_name = model_name\n",
    "        best_score = f1\n",
    "\n",
    "# Mostrar resultados\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"F1-Score\", ascending=False)\n",
    "print(\"\\nResultados finales:\")\n",
    "display(results_df)\n",
    "\n",
    "print(f\"\\nEl mejor modelo es: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de Hiperparámetros para el Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model_name in models_with_params:\n",
    "    print(\"\\nAjuste de hiperparámetros para el mejor modelo...\")\n",
    "    best_model_params = models_with_params[best_model_name][\"params\"]\n",
    "    grid_search = GridSearchCV(\n",
    "        models_with_params[best_model_name][\"model\"],\n",
    "        best_model_params,\n",
    "        scoring=\"f1\",\n",
    "        cv=3,\n",
    "        verbose=2,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train.values.ravel())\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    print(\"\\nMejores parámetros encontrados:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    # Evaluar el modelo con los mejores parámetros\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(\"\\nReporte de clasificación con el mejor modelo ajustado:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar el Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo ajustado\n",
    "joblib.dump(best_model, \"../models/best_model.pkl\")\n",
    "print(\"\\nEl mejor modelo ha sido guardado en '../models/best_model.pkl'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_product_development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
